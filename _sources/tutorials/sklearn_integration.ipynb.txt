{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn Integration\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/HLasse/TextDescriptives/blob/main/docs/tutorials/sklearn_integration.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "In the [introductory tutorial](https://hlasse.github.io/TextDescriptives/tutorials/introductory_tutorial.html) tutorial you learned how to use the components and extractors of TextDescriptives and saw how to use them for exploratory data analysis. \n",
    "\n",
    "In this tutorial we will walk through how to use TextDescriptives in a sklearn pipeline for e.g. text classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use the same dataset as in the introductory tutorial, i.e. the [SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
    "The dataset contains 5572 SMS messages categorized as ham or spam. \n",
    "\n",
    "Load's load the dataset and the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import textdescriptives\n",
    "    import sklearn\n",
    "except:\n",
    "    !pip install \"textdescriptives[tutorials]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the functionality of TextDescriptives in an sklearn pipeline, you simply need to instantiate `TextDecriptivesFeaturizer` with the same arguments as you would provide to `extract_metrics` and wrap it in a sklearn `Pipeline`. \n",
    "\n",
    "Let's try training a classifier on the SMS data using the `descriptive_stats` feature set as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textdescriptives.utils import load_sms_data\n",
    "df = load_sms_data()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, the \"message\" column contains the text we want to extract metrics from, and the \"label\" column contains the label. Now, let's instantiate the featurizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textdescriptives.integrations.sklearn_featurizer import TextDescriptivesFeaturizer\n",
    "\n",
    "# instantiate the featurizer with the same options as you would pass\n",
    "# to textdescriptives.extract_metrics\n",
    "descriptive_stats_extractor = TextDescriptivesFeaturizer(\n",
    "    lang=\"en\", metrics=[\"descriptive_stats\"]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to make the pipeline. Make sure to wrap the featurizer in a ColumnTransformer, as it's necessary to make sure the featurizer only operates on the \"message\" column, which is the column containing the text in this example.\n",
    "\n",
    "As there can be missing values values after extraction, we use a SimpleImputer to impute the missing values with the median.\n",
    "\n",
    "In the end, we use a RandomForestClassifier as the classifier, divide the data into a training and a test split and train and evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9417040358744395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import set_config\n",
    "\n",
    "# This tells sklearn to use pandas dataframes as output which means\n",
    "# it's easier to access the feature names\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"featurizer\",\n",
    "            ColumnTransformer(\n",
    "                [(\"text_processing\", descriptive_stats_extractor, \"message\")]\n",
    "            ,\n",
    "            # removes the `text_processing__` prefix from feature names\n",
    "            verbose_feature_names_out=False, \n",
    "            ),\n",
    "        ),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"classifier\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#  split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(\"label\", axis=1),\n",
    "    df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# fit the pipeline and evaluate\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Test accuracy:\", pipe.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! TextDescriptivesFeaturizer implements the `get_features_out` method, which means the feature names are passed on in the pipeline and allows us to get informative names for e.g. feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n_characters</td>\n",
       "      <td>0.164520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>token_length_mean</td>\n",
       "      <td>0.147599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>token_length_std</td>\n",
       "      <td>0.129877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n_unique_tokens</td>\n",
       "      <td>0.119566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n_tokens</td>\n",
       "      <td>0.085706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>syllables_per_token_std</td>\n",
       "      <td>0.051739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence_length_std</td>\n",
       "      <td>0.051531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>proportion_unique_tokens</td>\n",
       "      <td>0.050172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>syllables_per_token_mean</td>\n",
       "      <td>0.050141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence_length_mean</td>\n",
       "      <td>0.040784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence_length_median</td>\n",
       "      <td>0.038514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n_sentences</td>\n",
       "      <td>0.036295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>token_length_median</td>\n",
       "      <td>0.031954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>syllables_per_token_median</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Feature  Importance\n",
       "12                n_characters    0.164520\n",
       "0            token_length_mean    0.147599\n",
       "2             token_length_std    0.129877\n",
       "10             n_unique_tokens    0.119566\n",
       "9                     n_tokens    0.085706\n",
       "8      syllables_per_token_std    0.051739\n",
       "5          sentence_length_std    0.051531\n",
       "11    proportion_unique_tokens    0.050172\n",
       "6     syllables_per_token_mean    0.050141\n",
       "3         sentence_length_mean    0.040784\n",
       "4       sentence_length_median    0.038514\n",
       "13                 n_sentences    0.036295\n",
       "1          token_length_median    0.031954\n",
       "7   syllables_per_token_median    0.001601"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# extract feature importances\n",
    "feature_importance_mapping = list(\n",
    "    zip(\n",
    "        pipe[\"classifier\"].feature_names_in_,\n",
    "        pipe.named_steps[\"classifier\"].feature_importances_,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Feature importances:\")\n",
    "# sort by importance\n",
    "df_importances = pd.DataFrame(\n",
    "    feature_importance_mapping, columns=[\"Feature\", \"Importance\"]\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "df_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
